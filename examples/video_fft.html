<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Video example - three-projected-material</title>
    <link rel="stylesheet" href="css/style.css" type="text/css" />
   <!-- Import maps polyfill -->
        <!-- Remove this when import maps will be widely supported -->
        <script async src="./fft/js/es-module-shims.js"></script>
    <link rel="stylesheet" href="./css/style.css" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/css/bootstrap.min.css" integrity="sha384-rbsA2VBKQhggwzxH7pPCaAqO46MgnOM80zW1RWuH61DGLwZJEdK2Kadq2F9CUG65" crossorigin="anonymous">
   <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
   <script type="module" src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js" integrity="sha512-dLxUelApnYxpLt6K2iomGngnHO83iUvZytA3YjDUCjT0HDOHKXnVYdf3hU4JjM8uEhxf9nD1/ey98U3t2vZ0qQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>"></script>
   <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <style>
        body {
                overflow: hidden;
                margin: 0px;
            }
        </style>
  </head>
  <body>
    <canvas id="app"></canvas>



    <script type="module">
import * as THREE from './build2/three.module.js';
      import WebGLApp from './lib/WebGLApp.js'
      import ProjectedMaterial from './ProjectedMaterial.js'
      import { loadGltf } from './lib/three-utils.js'



        import { OrbitControls } from './fft/jsm/OrbitControls.js'
        import Stats from './fft/jsm/stats.module.js'




     </script>



    <body>

    <script>
                init();
                animate();
                function init() {

      // grab our canvas
      const canvas = document.querySelector('#app')
let WebGLApp;
// WebGLApp is a really basic wrapper around the three.js setup,
// it hides all unnecessary stuff not related to this example
const webgl = new WebGLApp({
  canvas,
  // set the scene background color
  background: '#000',
  // show the fps counter from stats.js
  showFps: true

// attach it to the window to inspect in the console
window.webgl = webgl
})
// create a video element and play it
const video = document.createElement('video')
video.src = './images/bigbucksbunny.mp4'
video.muted = true
video.loop = true
video.play()

// create the VideoTexture and enable gamma correction for it
const texture = new THREE.VideoTexture(video)



                     let t = 0;

                     const day = new THREE.Color(0xB8F4FF);
                     const duskdawn = new THREE.Color(0x3d1802);

                const scene = new THREE.Scene()

                const light = new THREE.AmbientLight()
                scene.add(light)
                scene.add(day)
                scene.add(duskdawn)

            const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000)
            camera.position.x = 7
            camera.position.y = 0.75
            camera.position.z = 10

            const renderer = new THREE.WebGLRenderer({
                antialias: true
              });
            renderer.setSize(window.innerWidth, window.innerHeight)
            document.body.appendChild(renderer.domElement)

            new OrbitControls(camera, renderer.domElement)

            const canvas2d = document.createElement('canvas')
            canvas2d.width = 256
            canvas2d.height = 512

            const ctx = canvas2d.getContext('2d')



            let alpha;
            let desynchronized;
            let colorSpace;
            let willReadFrequently;

            let ImageSmoothingQuality;

            let globalAlpha;
            let globalCompositeOperation;

            let imageSmoothingEnabled;
            let imageSmoothingQuality;


            alpha = 'true';
            desynchronized = 'true';
            colorSpace = 'hsl';
            willReadFrequently = 'true';

            globalAlpha = '.70';
            globalCompositeOperation = 'source-over';
            imageSmoothingEnabled = 'true';
            imageSmoothingQuality = 'high';



           // const texture2 = new THREE.Texture(canvas2d)
            //texture2.minFilter = THREE.LinearFilter
            //texture2.magFilter = THREE.LinearFilter
            })

      // create the video projector!
      const projector = new THREE.PerspectiveCamera(30, 16 / 9, 0.01, 2)
      projector.position.set(7, 0.75, 10)
      const helper = new THREE.CameraHelper(projector)
      const gui = webgl.gui.add({ showProjector: true }, 'showProjector')
      gui.onChange((showProjector) => {
        if (showProjector) {
          webgl.scene.add(helper)
        } else {
          webgl.scene.remove(helper)
        }
      })

      // find the screen object in the cinema model
    //  let screen
    //  cinemaModel.traverse((child) => {
       // if (child.name === 'screen') {
       //   screen = child
      //  }
     // })

      // assign the ProjectedMaterial to the screen
      const material = new ProjectedMaterial({
        camera: projector,
        texture,
        color: '#aaa', // the color of the remaining screen
      })

            const plane = new THREE.Mesh(
                new THREE.PlaneGeometry(20, 20, 256, 256),
                new THREE.MeshPhongMaterial({
                    wireframe: true,
                    color: new THREE.Color(0x34ebd2),
                    displacementMap: texture,
                    displacementScale: 10,
                })
            )

            let autorotate;
                plane.rotateX(-Math.PI / 3)
              autorotate = true;

            scene.add(plane)
            // load the cinema model



webgl.scene.add(PlaneGeometry)
            plane.material = material

// everything is set, project!
material.project(plane)

// add lights
const directionalLight = new THREE.DirectionalLight('#ffffff', 0.6)
directionalLight.position.set(0, 10, 10)
webgl.scene.add(directionalLight)

const ambientLight = new THREE.AmbientLight('#ffffff', 0.3)
webgl.scene.add(ambientLight)

// start animation loop
webgl.start()

            window.addEventListener('resize', onWindowResize, false)
            function onWindowResize() {
                camera.aspect = window.innerWidth / window.innerHeight
                camera.updateProjectionMatrix()
                renderer.setSize(window.innerWidth, window.innerHeight)
                render()
            }

            let context
            let analyser
            let mediaSource
            let imageData

            function getUserMedia(dictionary, callback) {
                try {
                    navigator.getUserMedia =
                        navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia
                    navigator.getUserMedia(dictionary, callback, (e) => {
                        console.dir(e)
                    })
                } catch (e) {
                    alert('getUserMedia threw exception :' + e)
                }
            }

            function connectAudioAPI() {
                try {
                    context = new AudioContext()
                    analyser = context.createAnalyser()
                    analyser.fftSize = 2048

                    navigator.mediaDevices
                        .getUserMedia({ audio: true, video: true })
                        .then(function (stream) {
                            mediaSource = context.createMediaStreamSource(stream)
                            mediaSource.connect(analyser)
                            animate()
                            context.resume()
                        })
                        .catch(function (err) {
                            alert(err)
                        })
                } catch (e) {
                    alert(e)
                }
            }

            function updateFFT() {
                let timeData = new Uint8Array(analyser.frequencyBinCount)

                analyser.getByteFrequencyData(timeData)

                imageData = ctx.getImageData(0, 1, 256, 511)
                ctx.putImageData(imageData, 0, 0, 0, 0, 256, 512)

                for (let x = 0; x < 256; x++) {
                    ctx.fillStyle = 'rgb(' + timeData[x] + ', 0, 0) '
                    ctx.fillRect(x, 510, 2, 2)
                }
console.log(timeData)
                texture.needsUpdate = true
            }

            const stats = new Stats()
            document.body.appendChild(stats.domElement)

            function animate() {
                requestAnimationFrame(animate)

                updateFFT()

                render()

                stats.update()
            }

            function render() {
                renderer.render(scene, camera)
            }

            window.onload = function () {
                connectAudioAPI()
                document.getElementById('song');
                song(play)
            }
                }
        </script>
        <audio id="song" autoplay controls>

            <source src="http://inoculate.media/assets/june.mp3" type="audio/mpeg">
          Your browser does not support the audio element.
          </audio>





  </body>
</html>
